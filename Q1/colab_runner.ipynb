{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# Q1: CIFAR-10 CNN - Colab Runner\n",
        "\n",
        "This notebook sets up GPU, installs dependencies, runs ablation, trains the optimal model, evaluates on test set, visualizes feature maps, and zips outputs for download.\n",
        "\n",
        "- Make sure to pick GPU: Runtime â†’ Change runtime type â†’ GPU\n",
        "- Choose ONE of the three project setup paths below: Google Drive, GitHub clone, or Zip upload.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check GPU\n",
        "import torch\n",
        "print('Torch:', torch.__version__)\n",
        "print('CUDA available:', torch.cuda.is_available())\n",
        "if torch.cuda.is_available():\n",
        "    print('GPU name:', torch.cuda.get_device_name(0))\n",
        "else:\n",
        "    print('Enable GPU in Runtime > Change runtime type')\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Project setup: choose one path below\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Option A: Mount Google Drive and use existing project in Drive (edit the path)\n",
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "PROJECT_DIR = '/content/drive/MyDrive/your_project_path/genai_A1'  # <-- EDIT THIS\n",
        "Q1_DIR = os.path.join(PROJECT_DIR, 'Q1')\n",
        "\n",
        "%cd $Q1_DIR\n",
        "os.environ['PYTHONPATH'] = Q1_DIR\n",
        "!pwd && ls -la\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Option B: Clone from GitHub (replace with your repo URL)\n",
        "import os\n",
        "\n",
        "%cd /content\n",
        "!git clone https://github.com/your/repo.git genai_A1\n",
        "%cd /content/genai_A1/Q1\n",
        "os.environ['PYTHONPATH'] = '/content/genai_A1/Q1'\n",
        "!pwd && ls -la\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Option C: Upload a ZIP and unzip to /content\n",
        "from google.colab import files\n",
        "import os\n",
        "\n",
        "uploaded = files.upload()  # upload your project zip\n",
        "zip_name = list(uploaded.keys())[0]\n",
        "!unzip -o \"$zip_name\" -d /content\n",
        "%cd /content/genai_A1/Q1\n",
        "os.environ['PYTHONPATH'] = '/content/genai_A1/Q1'\n",
        "!pwd && ls -la\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install dependencies\n",
        "%pip install -U pip\n",
        "%pip install -r /content/genai_A1/requirements.txt\n",
        "\n",
        "# Optional: Speed up HF datasets cache\n",
        "import os\n",
        "os.environ['HF_DATASETS_CACHE'] = '/content/hf_cache'\n",
        "!mkdir -p /content/hf_cache\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Ensure we are in Q1 dir and outputs exists\n",
        "import os, pathlib\n",
        "Q1_DIR = os.getcwd()\n",
        "print('Working dir:', Q1_DIR)\n",
        "os.makedirs('outputs', exist_ok=True)\n",
        "!ls -la\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ===============================================\n",
        "# TASK 1: Dataset Preparation & Testing\n",
        "# ===============================================\n",
        "print(\"ðŸš€ TASK 1: Testing Dataset Loading...\")\n",
        "\n",
        "# Test CIFAR-10 dataset loading from HuggingFace\n",
        "!python -c \"from src.dataset import CIFAR10HFDataset; ds = CIFAR10HFDataset(split='train[:100]'); print(f'âœ… Dataset loaded! Shape: {ds[0][0].shape}, Label: {ds[0][1]}, Classes: 10')\"\n",
        "\n",
        "# Test model creation\n",
        "!python -c \"from src.model import SimpleCNN; model = SimpleCNN(); print(f'âœ… Model created with {sum(p.numel() for p in model.parameters()):,} parameters')\"\n",
        "\n",
        "print(\"âœ… TASK 1 COMPLETE: Dataset and model verified!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ===============================================\n",
        "# TASK 2: Build CNN and Train with Training Curves\n",
        "# ===============================================\n",
        "print(\"ðŸ§  TASK 2: Training CNN with Training Curves...\")\n",
        "\n",
        "# Train baseline model (balanced epochs for good performance + reasonable time)\n",
        "!python -m src.train --epochs 25 --batch_size 128 --lr 0.001 --num_layers 3 --base_filters 32 --outdir outputs\n",
        "\n",
        "# Display training curve\n",
        "from IPython.display import Image, display\n",
        "print(\"ðŸ“ˆ Training Loss Curve:\")\n",
        "display(Image('outputs/loss_curve.png'))\n",
        "\n",
        "print(\"âœ… TASK 2 COMPLETE: CNN trained with training curves!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ===============================================\n",
        "# TASK 3: Model Evaluation with Confusion Matrix & Metrics\n",
        "# ===============================================\n",
        "print(\"ðŸ“Š TASK 3: Evaluating Model Performance...\")\n",
        "\n",
        "# Evaluate the trained model on test data\n",
        "!python -m src.evaluate --model_path outputs/best_model.pt --batch_size 128 --num_layers 3 --base_filters 32 --outdir outputs\n",
        "\n",
        "# Display results\n",
        "from IPython.display import Image, display\n",
        "import pandas as pd\n",
        "\n",
        "print(\"ðŸŽ¯ Confusion Matrix:\")\n",
        "display(Image('outputs/confusion_matrix.png'))\n",
        "\n",
        "print(\"ðŸ“‹ Performance Metrics:\")\n",
        "metrics = pd.read_csv('outputs/metrics.csv')\n",
        "display(metrics)\n",
        "\n",
        "print(\"ðŸ“Š Per-Class Performance:\")\n",
        "per_class = pd.read_csv('outputs/per_class_metrics.csv')\n",
        "display(per_class.head(10))\n",
        "\n",
        "print(\"âœ… TASK 3 COMPLETE: Model evaluated with confusion matrix and metrics!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ===============================================\n",
        "# TASK 4: Feature Map Visualization & Analysis\n",
        "# ===============================================\n",
        "print(\"ðŸ” TASK 4: Extracting and Visualizing Feature Maps...\")\n",
        "\n",
        "# Extract and visualize feature maps from different layers\n",
        "!python -m src.visualize_features --model_path outputs/best_model.pt --batch_size 128 --num_layers 3 --base_filters 32 --outdir outputs --num_samples 6\n",
        "\n",
        "# Display feature maps\n",
        "from IPython.display import Image, display\n",
        "import os\n",
        "\n",
        "print(\"ðŸŽ¨ Feature Maps from Different Convolutional Layers:\")\n",
        "display(Image('outputs/feature_maps.png'))\n",
        "\n",
        "print(\"ðŸ§  Layer-wise Feature Analysis:\")\n",
        "if os.path.exists('outputs/feature_analysis.txt'):\n",
        "    with open('outputs/feature_analysis.txt', 'r') as f:\n",
        "        print(f.read())\n",
        "\n",
        "print(\"âœ… TASK 4 COMPLETE: Feature maps visualized and analyzed!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ===============================================\n",
        "# TASK 5: Hyperparameter Ablation Study\n",
        "# ===============================================\n",
        "print(\"âš¡ TASK 5: Running Comprehensive Ablation Study...\")\n",
        "print(\"Testing: Learning Rate, Batch Size, Conv Filters, Number of Layers\")\n",
        "\n",
        "# Run ablation study (balanced epochs for thorough comparison)\n",
        "!python -m src.ablation_study --outdir outputs --epochs 15\n",
        "\n",
        "# Display results\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(\"ðŸ“Š Ablation Study Results:\")\n",
        "ablation_results = pd.read_csv('outputs/ablation_results.csv')\n",
        "display(ablation_results)\n",
        "\n",
        "print(\"ðŸ† Best Hyperparameter Configurations:\")\n",
        "if os.path.exists('outputs/best_ablation_configs.json'):\n",
        "    import json\n",
        "    with open('outputs/best_ablation_configs.json', 'r') as f:\n",
        "        best_configs = json.load(f)\n",
        "    for exp_type, config in best_configs.items():\n",
        "        print(f\"{exp_type}: {config}\")\n",
        "\n",
        "print(\"âœ… TASK 5 COMPLETE: Ablation study finished!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ===============================================\n",
        "# TASK 6: Optimal Model Training & Performance Comparison\n",
        "# ===============================================\n",
        "print(\"ðŸ† TASK 6: Training Optimal Model and Comparing Performance...\")\n",
        "\n",
        "# Train model with optimal hyperparameters (more epochs for best performance)\n",
        "!python -m src.train_optimal --epochs 30 --best_config_file outputs/best_ablation_configs.json --outdir outputs\n",
        "\n",
        "# Evaluate optimal model\n",
        "!python -m src.evaluate --model_path outputs/optimal_model.pt --batch_size 128 --outdir outputs\n",
        "\n",
        "# Display comparison results\n",
        "import pandas as pd\n",
        "from IPython.display import Image, display\n",
        "\n",
        "print(\"ðŸ“ˆ Optimal Model Training Curves:\")\n",
        "if os.path.exists('outputs/optimal_training_curves.png'):\n",
        "    display(Image('outputs/optimal_training_curves.png'))\n",
        "\n",
        "print(\"âš–ï¸ Model Performance Comparison:\")\n",
        "if os.path.exists('outputs/model_comparison.csv'):\n",
        "    comparison = pd.read_csv('outputs/model_comparison.csv')\n",
        "    display(comparison)\n",
        "\n",
        "print(\"âœ… TASK 6 COMPLETE: Optimal model trained and compared!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ===============================================\n",
        "# SUMMARY & RESULTS OVERVIEW\n",
        "# ===============================================\n",
        "print(\"ðŸ“‹ FINAL RESULTS SUMMARY\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# List all generated files\n",
        "print(\"ðŸ“ Generated Files:\")\n",
        "!ls -la outputs/\n",
        "\n",
        "# Show key metrics\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "if os.path.exists('outputs/metrics.csv'):\n",
        "    print(\"\\nðŸŽ¯ Final Model Performance:\")\n",
        "    metrics = pd.read_csv('outputs/metrics.csv')\n",
        "    display(metrics)\n",
        "\n",
        "if os.path.exists('outputs/model_comparison.csv'):\n",
        "    print(\"\\nâš–ï¸ Baseline vs Optimal Model:\")\n",
        "    comparison = pd.read_csv('outputs/model_comparison.csv')\n",
        "    display(comparison)\n",
        "\n",
        "if os.path.exists('outputs/ablation_results.csv'):\n",
        "    print(\"\\nðŸ“Š Best Hyperparameters Found:\")\n",
        "    ablation = pd.read_csv('outputs/ablation_results.csv')\n",
        "    best_row = ablation.loc[ablation['accuracy'].idxmax()]\n",
        "    print(f\"Best Configuration: {best_row.to_dict()}\")\n",
        "\n",
        "print(\"\\nðŸŽ‰ ALL TASKS COMPLETED SUCCESSFULLY!\")\n",
        "print(\"âœ… Dataset loaded and preprocessed\")\n",
        "print(\"âœ… CNN trained with training curves\")\n",
        "print(\"âœ… Model evaluated with confusion matrix\")\n",
        "print(\"âœ… Feature maps visualized and analyzed\")\n",
        "print(\"âœ… Hyperparameter ablation study completed\")\n",
        "print(\"âœ… Optimal model trained and compared\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ===============================================\n",
        "# DOWNLOAD ALL RESULTS - Q1_OUTPUTS\n",
        "# ===============================================\n",
        "print(\"ðŸ“¦ Preparing Q1_OUTPUTS for download...\")\n",
        "\n",
        "# Show what files we generated\n",
        "print(\"ðŸ“ Generated Files:\")\n",
        "!ls -la outputs/\n",
        "\n",
        "# Create single comprehensive ZIP file\n",
        "print(\"\\nðŸ—œï¸ Creating Q1_OUTPUTS.zip...\")\n",
        "!zip -r /content/Q1_OUTPUTS.zip outputs/ -x \"*.pyc\" \"*__pycache__*\"\n",
        "\n",
        "# Download the complete package\n",
        "from google.colab import files\n",
        "print(\"\\nâ¬‡ï¸ Downloading Q1_OUTPUTS.zip to your local CPU...\")\n",
        "files.download('/content/Q1_OUTPUTS.zip')\n",
        "\n",
        "print(\"\\nâœ… DOWNLOAD COMPLETE!\")\n",
        "print(\"ðŸ“¦ File downloaded: Q1_OUTPUTS.zip\")\n",
        "print(\"ðŸ’» Check your Downloads folder\")\n",
        "\n",
        "print(\"\\nðŸ“‹ Your Q1_OUTPUTS.zip contains:\")\n",
        "print(\"ðŸ”¹ All model checkpoints (.pt files)\")\n",
        "print(\"ðŸ”¹ Training curves and loss plots\")\n",
        "print(\"ðŸ”¹ Confusion matrix visualization\")\n",
        "print(\"ðŸ”¹ Performance metrics tables\")\n",
        "print(\"ðŸ”¹ Feature map visualizations\")\n",
        "print(\"ðŸ”¹ Complete ablation study results\")\n",
        "print(\"ðŸ”¹ Model comparison data\")\n",
        "print(\"ðŸ”¹ All generated analyses and plots\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ===============================================\n",
        "# EXTRACT AND ANALYZE RESULTS LOCALLY\n",
        "# ===============================================\n",
        "print(\"ðŸ“ Instructions for using your Q1_OUTPUTS.zip:\")\n",
        "print(\"\\n1. ðŸ“‚ Go to your Downloads folder\")\n",
        "print(\"2. ðŸ—œï¸ Extract Q1_OUTPUTS.zip\")\n",
        "print(\"3. ðŸ“Š Open the 'outputs' folder\")\n",
        "print(\"4. ðŸ” Explore your results:\")\n",
        "\n",
        "print(\"\\n   ðŸ“ˆ Training Analysis:\")\n",
        "print(\"   - loss_curve.png - Training progress\")\n",
        "print(\"   - optimal_training_curves.png - Best model training\")\n",
        "\n",
        "print(\"\\n   ðŸŽ¯ Model Performance:\")\n",
        "print(\"   - confusion_matrix.png - Classification results\")\n",
        "print(\"   - metrics.csv - Accuracy, precision, recall, F1\")\n",
        "print(\"   - per_class_metrics.csv - Per-class performance\")\n",
        "\n",
        "print(\"\\n   ðŸ”¬ Feature Analysis:\")\n",
        "print(\"   - feature_maps.png - What CNN layers learned\")\n",
        "print(\"   - feature_analysis.txt - Layer analysis\")\n",
        "\n",
        "print(\"\\n   âš¡ Hyperparameter Study:\")\n",
        "print(\"   - ablation_results.csv - All tested configurations\")\n",
        "print(\"   - best_ablation_configs.json - Optimal settings\")\n",
        "\n",
        "print(\"\\n   âš–ï¸ Model Comparison:\")\n",
        "print(\"   - model_comparison.csv - Baseline vs Optimal\")\n",
        "\n",
        "print(\"\\n   ðŸ¤– Model Files:\")\n",
        "print(\"   - best_model.pt - Baseline trained model\")\n",
        "print(\"   - optimal_model.pt - Best hyperparameter model\")\n",
        "\n",
        "print(\"\\nðŸŽ‰ All 6 tasks completed successfully!\")\n",
        "print(\"ðŸš€ Your complete Q1 analysis is ready for review!\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}

{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# Q1: CIFAR-10 CNN - Colab Runner\n",
        "\n",
        "This notebook sets up GPU, installs dependencies, runs ablation, trains the optimal model, evaluates on test set, visualizes feature maps, and zips outputs for download.\n",
        "\n",
        "- Make sure to pick GPU: Runtime → Change runtime type → GPU\n",
        "- Choose ONE of the three project setup paths below: Google Drive, GitHub clone, or Zip upload.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check GPU\n",
        "import torch\n",
        "print('Torch:', torch.__version__)\n",
        "print('CUDA available:', torch.cuda.is_available())\n",
        "if torch.cuda.is_available():\n",
        "    print('GPU name:', torch.cuda.get_device_name(0))\n",
        "else:\n",
        "    print('Enable GPU in Runtime > Change runtime type')\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Project setup: choose one path below\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Option A: Mount Google Drive and use existing project in Drive (edit the path)\n",
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "PROJECT_DIR = '/content/drive/MyDrive/your_project_path/genai_A1'  # <-- EDIT THIS\n",
        "Q1_DIR = os.path.join(PROJECT_DIR, 'Q1')\n",
        "\n",
        "%cd $Q1_DIR\n",
        "os.environ['PYTHONPATH'] = Q1_DIR\n",
        "!pwd && ls -la\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Option B: Clone from GitHub (replace with your repo URL)\n",
        "import os\n",
        "\n",
        "%cd /content\n",
        "!git clone https://github.com/your/repo.git genai_A1\n",
        "%cd /content/genai_A1/Q1\n",
        "os.environ['PYTHONPATH'] = '/content/genai_A1/Q1'\n",
        "!pwd && ls -la\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Option C: Upload a ZIP and unzip to /content\n",
        "from google.colab import files\n",
        "import os\n",
        "\n",
        "uploaded = files.upload()  # upload your project zip\n",
        "zip_name = list(uploaded.keys())[0]\n",
        "!unzip -o \"$zip_name\" -d /content\n",
        "%cd /content/genai_A1/Q1\n",
        "os.environ['PYTHONPATH'] = '/content/genai_A1/Q1'\n",
        "!pwd && ls -la\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install dependencies\n",
        "%pip install -U pip\n",
        "%pip install -r /content/genai_A1/requirements.txt\n",
        "\n",
        "# Optional: Speed up HF datasets cache\n",
        "import os\n",
        "os.environ['HF_DATASETS_CACHE'] = '/content/hf_cache'\n",
        "!mkdir -p /content/hf_cache\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Ensure we are in Q1 dir and outputs exists\n",
        "import os, pathlib\n",
        "Q1_DIR = os.getcwd()\n",
        "print('Working dir:', Q1_DIR)\n",
        "os.makedirs('outputs', exist_ok=True)\n",
        "!ls -la\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ===============================================\n",
        "# TASK 1: Dataset Preparation & Testing\n",
        "# ===============================================\n",
        "print(\"🚀 TASK 1: Testing Dataset Loading...\")\n",
        "\n",
        "# Test CIFAR-10 dataset loading from HuggingFace\n",
        "!python -c \"from src.dataset import CIFAR10HFDataset; ds = CIFAR10HFDataset(split='train[:100]'); print(f'✅ Dataset loaded! Shape: {ds[0][0].shape}, Label: {ds[0][1]}, Classes: 10')\"\n",
        "\n",
        "# Test model creation\n",
        "!python -c \"from src.model import SimpleCNN; model = SimpleCNN(); print(f'✅ Model created with {sum(p.numel() for p in model.parameters()):,} parameters')\"\n",
        "\n",
        "print(\"✅ TASK 1 COMPLETE: Dataset and model verified!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ===============================================\n",
        "# TASK 2: Build CNN and Train with Training Curves\n",
        "# ===============================================\n",
        "print(\"🧠 TASK 2: Training CNN with Training Curves...\")\n",
        "\n",
        "# Train baseline model (balanced epochs for good performance + reasonable time)\n",
        "!python -m src.train --epochs 25 --batch_size 128 --lr 0.001 --num_layers 3 --base_filters 32 --outdir outputs\n",
        "\n",
        "# Display training curve\n",
        "from IPython.display import Image, display\n",
        "print(\"📈 Training Loss Curve:\")\n",
        "display(Image('outputs/loss_curve.png'))\n",
        "\n",
        "print(\"✅ TASK 2 COMPLETE: CNN trained with training curves!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ===============================================\n",
        "# TASK 3: Model Evaluation with Confusion Matrix & Metrics\n",
        "# ===============================================\n",
        "print(\"📊 TASK 3: Evaluating Model Performance...\")\n",
        "\n",
        "# Evaluate the trained model on test data\n",
        "!python -m src.evaluate --model_path outputs/best_model.pt --batch_size 128 --num_layers 3 --base_filters 32 --outdir outputs\n",
        "\n",
        "# Display results\n",
        "from IPython.display import Image, display\n",
        "import pandas as pd\n",
        "\n",
        "print(\"🎯 Confusion Matrix:\")\n",
        "display(Image('outputs/confusion_matrix.png'))\n",
        "\n",
        "print(\"📋 Performance Metrics:\")\n",
        "metrics = pd.read_csv('outputs/metrics.csv')\n",
        "display(metrics)\n",
        "\n",
        "print(\"📊 Per-Class Performance:\")\n",
        "per_class = pd.read_csv('outputs/per_class_metrics.csv')\n",
        "display(per_class.head(10))\n",
        "\n",
        "print(\"✅ TASK 3 COMPLETE: Model evaluated with confusion matrix and metrics!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ===============================================\n",
        "# TASK 4: Feature Map Visualization & Analysis\n",
        "# ===============================================\n",
        "print(\"🔍 TASK 4: Extracting and Visualizing Feature Maps...\")\n",
        "\n",
        "# Extract and visualize feature maps from different layers\n",
        "!python -m src.visualize_features --model_path outputs/best_model.pt --batch_size 128 --num_layers 3 --base_filters 32 --outdir outputs --num_samples 6\n",
        "\n",
        "# Display feature maps\n",
        "from IPython.display import Image, display\n",
        "import os\n",
        "\n",
        "print(\"🎨 Feature Maps from Different Convolutional Layers:\")\n",
        "display(Image('outputs/feature_maps.png'))\n",
        "\n",
        "print(\"🧠 Layer-wise Feature Analysis:\")\n",
        "if os.path.exists('outputs/feature_analysis.txt'):\n",
        "    with open('outputs/feature_analysis.txt', 'r') as f:\n",
        "        print(f.read())\n",
        "\n",
        "print(\"✅ TASK 4 COMPLETE: Feature maps visualized and analyzed!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ===============================================\n",
        "# TASK 5: Hyperparameter Ablation Study\n",
        "# ===============================================\n",
        "print(\"⚡ TASK 5: Running Comprehensive Ablation Study...\")\n",
        "print(\"Testing: Learning Rate, Batch Size, Conv Filters, Number of Layers\")\n",
        "\n",
        "# Run ablation study (balanced epochs for thorough comparison)\n",
        "!python -m src.ablation_study --outdir outputs --epochs 15\n",
        "\n",
        "# Display results\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(\"📊 Ablation Study Results:\")\n",
        "ablation_results = pd.read_csv('outputs/ablation_results.csv')\n",
        "display(ablation_results)\n",
        "\n",
        "print(\"🏆 Best Hyperparameter Configurations:\")\n",
        "if os.path.exists('outputs/best_ablation_configs.json'):\n",
        "    import json\n",
        "    with open('outputs/best_ablation_configs.json', 'r') as f:\n",
        "        best_configs = json.load(f)\n",
        "    for exp_type, config in best_configs.items():\n",
        "        print(f\"{exp_type}: {config}\")\n",
        "\n",
        "print(\"✅ TASK 5 COMPLETE: Ablation study finished!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ===============================================\n",
        "# TASK 6: Optimal Model Training & Performance Comparison\n",
        "# ===============================================\n",
        "print(\"🏆 TASK 6: Training Optimal Model and Comparing Performance...\")\n",
        "\n",
        "# Train model with optimal hyperparameters (more epochs for best performance)\n",
        "!python -m src.train_optimal --epochs 30 --best_config_file outputs/best_ablation_configs.json --outdir outputs\n",
        "\n",
        "# Evaluate optimal model\n",
        "!python -m src.evaluate --model_path outputs/optimal_model.pt --batch_size 128 --outdir outputs\n",
        "\n",
        "# Display comparison results\n",
        "import pandas as pd\n",
        "from IPython.display import Image, display\n",
        "\n",
        "print(\"📈 Optimal Model Training Curves:\")\n",
        "if os.path.exists('outputs/optimal_training_curves.png'):\n",
        "    display(Image('outputs/optimal_training_curves.png'))\n",
        "\n",
        "print(\"⚖️ Model Performance Comparison:\")\n",
        "if os.path.exists('outputs/model_comparison.csv'):\n",
        "    comparison = pd.read_csv('outputs/model_comparison.csv')\n",
        "    display(comparison)\n",
        "\n",
        "print(\"✅ TASK 6 COMPLETE: Optimal model trained and compared!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ===============================================\n",
        "# SUMMARY & RESULTS OVERVIEW\n",
        "# ===============================================\n",
        "print(\"📋 FINAL RESULTS SUMMARY\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# List all generated files\n",
        "print(\"📁 Generated Files:\")\n",
        "!ls -la outputs/\n",
        "\n",
        "# Show key metrics\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "if os.path.exists('outputs/metrics.csv'):\n",
        "    print(\"\\n🎯 Final Model Performance:\")\n",
        "    metrics = pd.read_csv('outputs/metrics.csv')\n",
        "    display(metrics)\n",
        "\n",
        "if os.path.exists('outputs/model_comparison.csv'):\n",
        "    print(\"\\n⚖️ Baseline vs Optimal Model:\")\n",
        "    comparison = pd.read_csv('outputs/model_comparison.csv')\n",
        "    display(comparison)\n",
        "\n",
        "if os.path.exists('outputs/ablation_results.csv'):\n",
        "    print(\"\\n📊 Best Hyperparameters Found:\")\n",
        "    ablation = pd.read_csv('outputs/ablation_results.csv')\n",
        "    best_row = ablation.loc[ablation['accuracy'].idxmax()]\n",
        "    print(f\"Best Configuration: {best_row.to_dict()}\")\n",
        "\n",
        "print(\"\\n🎉 ALL TASKS COMPLETED SUCCESSFULLY!\")\n",
        "print(\"✅ Dataset loaded and preprocessed\")\n",
        "print(\"✅ CNN trained with training curves\")\n",
        "print(\"✅ Model evaluated with confusion matrix\")\n",
        "print(\"✅ Feature maps visualized and analyzed\")\n",
        "print(\"✅ Hyperparameter ablation study completed\")\n",
        "print(\"✅ Optimal model trained and compared\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ===============================================\n",
        "# DOWNLOAD ALL RESULTS - Q1_OUTPUTS\n",
        "# ===============================================\n",
        "print(\"📦 Preparing Q1_OUTPUTS for download...\")\n",
        "\n",
        "# Show what files we generated\n",
        "print(\"📁 Generated Files:\")\n",
        "!ls -la outputs/\n",
        "\n",
        "# Create single comprehensive ZIP file\n",
        "print(\"\\n🗜️ Creating Q1_OUTPUTS.zip...\")\n",
        "!zip -r /content/Q1_OUTPUTS.zip outputs/ -x \"*.pyc\" \"*__pycache__*\"\n",
        "\n",
        "# Download the complete package\n",
        "from google.colab import files\n",
        "print(\"\\n⬇️ Downloading Q1_OUTPUTS.zip to your local CPU...\")\n",
        "files.download('/content/Q1_OUTPUTS.zip')\n",
        "\n",
        "print(\"\\n✅ DOWNLOAD COMPLETE!\")\n",
        "print(\"📦 File downloaded: Q1_OUTPUTS.zip\")\n",
        "print(\"💻 Check your Downloads folder\")\n",
        "\n",
        "print(\"\\n📋 Your Q1_OUTPUTS.zip contains:\")\n",
        "print(\"🔹 All model checkpoints (.pt files)\")\n",
        "print(\"🔹 Training curves and loss plots\")\n",
        "print(\"🔹 Confusion matrix visualization\")\n",
        "print(\"🔹 Performance metrics tables\")\n",
        "print(\"🔹 Feature map visualizations\")\n",
        "print(\"🔹 Complete ablation study results\")\n",
        "print(\"🔹 Model comparison data\")\n",
        "print(\"🔹 All generated analyses and plots\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ===============================================\n",
        "# EXTRACT AND ANALYZE RESULTS LOCALLY\n",
        "# ===============================================\n",
        "print(\"📁 Instructions for using your Q1_OUTPUTS.zip:\")\n",
        "print(\"\\n1. 📂 Go to your Downloads folder\")\n",
        "print(\"2. 🗜️ Extract Q1_OUTPUTS.zip\")\n",
        "print(\"3. 📊 Open the 'outputs' folder\")\n",
        "print(\"4. 🔍 Explore your results:\")\n",
        "\n",
        "print(\"\\n   📈 Training Analysis:\")\n",
        "print(\"   - loss_curve.png - Training progress\")\n",
        "print(\"   - optimal_training_curves.png - Best model training\")\n",
        "\n",
        "print(\"\\n   🎯 Model Performance:\")\n",
        "print(\"   - confusion_matrix.png - Classification results\")\n",
        "print(\"   - metrics.csv - Accuracy, precision, recall, F1\")\n",
        "print(\"   - per_class_metrics.csv - Per-class performance\")\n",
        "\n",
        "print(\"\\n   🔬 Feature Analysis:\")\n",
        "print(\"   - feature_maps.png - What CNN layers learned\")\n",
        "print(\"   - feature_analysis.txt - Layer analysis\")\n",
        "\n",
        "print(\"\\n   ⚡ Hyperparameter Study:\")\n",
        "print(\"   - ablation_results.csv - All tested configurations\")\n",
        "print(\"   - best_ablation_configs.json - Optimal settings\")\n",
        "\n",
        "print(\"\\n   ⚖️ Model Comparison:\")\n",
        "print(\"   - model_comparison.csv - Baseline vs Optimal\")\n",
        "\n",
        "print(\"\\n   🤖 Model Files:\")\n",
        "print(\"   - best_model.pt - Baseline trained model\")\n",
        "print(\"   - optimal_model.pt - Best hyperparameter model\")\n",
        "\n",
        "print(\"\\n🎉 All 6 tasks completed successfully!\")\n",
        "print(\"🚀 Your complete Q1 analysis is ready for review!\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
